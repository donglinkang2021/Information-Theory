{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Theory\n",
    "\n",
    "> 信息就是一个二进制序列，\n",
    ">\n",
    "> 也就是说不管信息量多大都全部编码成二进制，那我们就可以用二进制序列的长度来表示信息量的大小。\n",
    "\n",
    "学习一下信息论\n",
    "\n",
    "**reference** \n",
    "- https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/information-theory.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-information\n",
    "\n",
    "> 一个二进制信息长度\n",
    "\n",
    "$$\n",
    "I(X) = - \\log_2 (p)\n",
    "$$\n",
    "\n",
    "$$\n",
    "I(\\textrm{\"0010\"}) = - \\log (p(\\textrm{\"0010\"})) = - \\log \\left( \\frac{1}{2^4} \\right) = 4 \\textrm{ bits}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def nansum(x):\n",
    "    # Define nansum, as pytorch does not offer it inbuilt.\n",
    "    return x[~torch.isnan(x)].sum()\n",
    "\n",
    "def self_information(p):\n",
    "    return -torch.log2(torch.tensor(p)).item()\n",
    "\n",
    "self_information(1 / 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy\n",
    "\n",
    "> 一堆二进制信息长度的期望值\n",
    "\n",
    "### Definition\n",
    "\n",
    "For any random variable $X$ that follows a probability distribution with a probability density function (p.d.f.) or a probability mass function (p.m.f.) $p(x)$, we measure the expected amount of information through entropy (or Shannon entropy):\n",
    "\n",
    "$$\n",
    "H(X) = \\mathbb{E}_{x \\sim P}[I(x)] = - \\sum_{x \\in \\mathcal{X}} p(x) \\log p(x).\n",
    "$$\n",
    "\n",
    "where\n",
    "- $H(X)$ is the entropy of random variable $X$.\n",
    "- $\\mathcal{X}$ is the set of all possible outcomes of $X$.\n",
    "- $p(x)$ is the p.d.f. or p.m.f. of $X$.\n",
    "- $I(x) = - \\log p(x)$ is the self-information of outcome $x$.\n",
    "- $\\mathbb{E}_{x \\sim P}$ is the expectation of $x$ that follows the distribution $P$.\n",
    "- $H(X)$ is the average amount(expected value) of information of $X$.\n",
    "\n",
    "If $X$ is discrete, then\n",
    "\n",
    "$$\n",
    "H(X) = - \\sum_i p_i \\log p_i \\textrm{, where } p_i = P(X_i).\n",
    "$$\n",
    "\n",
    "If $X$ is continuous, then\n",
    "\n",
    "$$\n",
    "H(X) = - \\int_x p(x) \\log p(x) \\; dx.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6855)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entropy(p):\n",
    "    entropy = - p * torch.log2(p)\n",
    "    # Operator `nansum` will sum up the non-nan number\n",
    "    out = nansum(entropy)\n",
    "    return out\n",
    "\n",
    "entropy(torch.tensor([0.1, 0.5, 0.1, 0.3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties\n",
    "\n",
    "\n",
    "\n",
    "- $H(X) \\geq 0$ for any random variable $X$.\n",
    "  - $H(X) = 0$ if and only if $X$ is deterministic. (After `log` operation, the value is 0 while all the probability is 1.)\n",
    "> 信息长度肯定大于等于零，等于零的时候信息肯定是一串确定不变的东西，没任何含义。\n",
    "\n",
    "- $H(X) \\leq \\log |\\mathcal{X}|$ for any random variable $X$.\n",
    "  - $H(X) = \\log |\\mathcal{X}|$ if and only if $X$ is a uniform distribution.\n",
    "$$\n",
    "H(X) \\leq \\log(k), \\textrm{ with equality if and only if } p_i = \\frac{1}{k}, \\forall i.\n",
    "$$\n",
    "\n",
    "> 一堆二进制信息的长度期望值肯定小于等于二进制信息编码长度（信息样本空间的对数），等于的条件是样本空间中每种信息肯定是均匀分布。\n",
    "\n",
    "- If $X \\sim P$ and we try to encode $X$ with a code $f$, then the expected code length is $\\mathbb{E}_{x \\sim P}[l(f(x))] = \\sum_{x \\in \\mathcal{X}} p(x) l(f(x))$.\n",
    "  - $H(X)$ is the minimum expected code length among all possible codes.\n",
    "  - $H(X)$ is the minimum number of bits required to encode $X$.\n",
    "\n",
    "$$\n",
    "H(X) = - E_{x \\sim P} [\\log p(x)] \\leq  - E_{x \\sim P} [\\log q(x)], \\textrm{ with equality if and only if } P = Q.\n",
    "$$\n",
    "> 说白了就是我想用一个函数来刻画这个信息，但最小期望信息长度肯定还是信息本身长度，函数的期望信息长度肯定大于等于信息本身，所以最小期望信息长度就是信息本身。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information\n",
    "\n",
    "> 学习两种信息之间的关系，上面的信息都是单个信息的（单个分布），这里是两个信息之间的关系。（多个分布）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Entropy\n",
    "\n",
    "> 两个信息共同想要表达的东西的长度期望值\n",
    "\n",
    "> 一堆 两个信息的联合信息的长度期望值 (用一条信息表示两条信息)\n",
    "\n",
    "$$\n",
    "H(X, Y) =  -E_{(x, y) \\sim P} [\\log p_{X, Y}(x, y)].\n",
    "$$\n",
    "\n",
    "if $(X,Y) is a pair of discrete random variables, then\n",
    "\n",
    "$$\n",
    "H(X, Y) = - \\sum_{x} \\sum_{y} p_{X, Y}(x, y) \\log p_{X, Y}(x, y).\n",
    "$$\n",
    "\n",
    "if $(X,Y) is a pair of continuous random variables, then\n",
    "\n",
    "$$\n",
    "H(X, Y) = - \\int_{x, y} p_{X, Y}(x, y) \\ \\log p_{X, Y}(x, y) \\;dx \\;dy.\n",
    "$$\n",
    "\n",
    "#### Properties\n",
    "\n",
    "- $H(X, Y) = H(X) + H(Y)$ if and only if $X$ and $Y$ are independent.\n",
    "\n",
    "> 当这两条信息毫无关联的时候，联合信息长度肯定等于两个单独信息的信息长度之和。不然没法表示两条信息。\n",
    "\n",
    "- $H(X, Y) = H(X) = H(Y)$ if and only if $X$ and $Y$ are identical.(means $X$ and $Y$ are the same random variable)\n",
    "\n",
    "> 当这两条信息完全相同的时候，随便用其中一条就能表示两条了，所以联合信息长度等于单独信息长度。\n",
    "\n",
    "- Always\n",
    "$$\n",
    "H(X), H(Y) \\le H(X, Y) \\le H(X) + H(Y).\n",
    "$$\n",
    "> 两个信息的联合信息长度肯定小于等于两个单独信息的信息长度之和，大于等于任一单独信息的信息长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6855)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def joint_entropy(p_xy):\n",
    "    joint_ent = -p_xy * torch.log2(p_xy)\n",
    "    # Operator `nansum` will sum up the non-nan number\n",
    "    out = nansum(joint_ent)\n",
    "    return out\n",
    "\n",
    "joint_entropy(torch.tensor([[0.1, 0.5], [0.1, 0.3]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Entropy\n",
    "\n",
    "> 两个信息中，一条信息基于另一条信息想要表达的东西的长度期望值\n",
    "\n",
    "> 一堆 一条信息的条件信息的长度期望值 (用一条信息表示另一条信息)\n",
    "\n",
    "$$\n",
    "H(Y|X) = E_{(x, y) \\sim P} [ I(y|x) ] = -E_{(x, y) \\sim P} [\\log p_{Y|X}(y|x)]= - \\sum_{x \\in \\mathcal{X}} \\sum_{y \\in \\mathcal{Y}} p(x, y) \\log p(y|x).\n",
    "$$\n",
    "\n",
    "if $(X,Y)$ is a pair of discrete random variables, then\n",
    "\n",
    "$$\n",
    "H(Y \\mid X) = - \\sum_{x} \\sum_{y} p(x, y) \\log p(y \\mid x).\n",
    "$$\n",
    "\n",
    "if $(X,Y)$ is a pair of continuous random variables, then\n",
    "\n",
    "$$\n",
    "H(Y \\mid X) = - \\int_x \\int_y p(x, y) \\ \\log p(y \\mid x) \\;dx \\;dy.\n",
    "$$\n",
    "\n",
    "#### Properties\n",
    "\n",
    "$$\n",
    "H(Y \\mid X) = H(X, Y) - H(X).\n",
    "$$\n",
    "\n",
    "> 一条信息的条件信息长度等于这条信息和另一条信息的联合信息长度减去另一条信息的信息长度。\n",
    "> \n",
    "> 换种说法，`Y`信息基于`X`信息的信息量等于`Y`信息和`X`信息的联合信息量减去`X`信息的信息量。\n",
    "> - `Y`信息基于`X`信息的信息量的意思就是`X`已经表达了的东西`Y`不需要再表达"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8635)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conditional_entropy(p_xy, p_x):\n",
    "    p_y_given_x = p_xy/p_x\n",
    "    cond_ent = -p_xy * torch.log2(p_y_given_x)\n",
    "    # Operator `nansum` will sum up the non-nan number\n",
    "    out = nansum(cond_ent)\n",
    "    return out\n",
    "\n",
    "conditional_entropy(\n",
    "    torch.tensor([[0.1, 0.5], [0.2, 0.3]]),\n",
    "    torch.tensor([0.2, 0.8])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information\n",
    "\n",
    "> 两个信息的共享信息量\n",
    "\n",
    "$$\n",
    "I(X, Y) = H(X, Y) - H(Y \\mid X) - H(X \\mid Y).\n",
    "$$\n",
    "\n",
    "Expand it\n",
    "$$\n",
    "I(X, Y) = E_{x} E_{y} \\left\\{ p_{X, Y}(x, y) \\log\\frac{p_{X, Y}(x, y)}{p_X(x) p_Y(y)} \\right\\}.\n",
    "$$\n",
    "\n",
    "where\n",
    "- $I(X, Y)$ is the mutual information between $X$ and $Y$.\n",
    "- $H(X, Y)$ is the joint entropy of $X$ and $Y$.\n",
    "- $H(X \\mid Y)$ is the conditional entropy of $X$ given $Y$.\n",
    "- $H(Y \\mid X)$ is the conditional entropy of $Y$ given $X$.\n",
    "- $p_{X, Y}(x, y)$ is the joint p.d.f. or p.m.f. of $X$ and $Y$.\n",
    "- $p_X(x)$ is the p.d.f. or p.m.f. of $X$.\n",
    "- $p_Y(y)$ is the p.d.f. or p.m.f. of $Y$.\n",
    "- $E_{x}$ is the expectation of $x$.\n",
    "- $E_{y}$ is the expectation of $y$.\n",
    "\n",
    "Also, we have the following statements equivalent to the definition of mutual information:\n",
    "- $I(X, Y) = H(X) - H(X \\mid Y)$\n",
    "- $I(X, Y) = H(Y) - H(Y \\mid X)$\n",
    "- $I(X, Y) = H(X) + H(Y) - H(X, Y)$ \n",
    "\n",
    "![mutual-information](image/mutual-information.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7195)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mutual_information(p_xy, p_x, p_y):\n",
    "    p = p_xy / (p_x * p_y)\n",
    "    mutual = p_xy * torch.log2(p)\n",
    "    # Operator `nansum` will sum up the non-nan number\n",
    "    out = nansum(mutual)\n",
    "    return out\n",
    "\n",
    "mutual_information(\n",
    "    p_xy = torch.tensor([\n",
    "        [0.1, 0.5], \n",
    "        [0.1, 0.3]\n",
    "    ]),\n",
    "    p_x = torch.tensor(\n",
    "        [0.2, 0.8]\n",
    "    ), \n",
    "    p_y = torch.tensor([\n",
    "        [0.75, 0.25]\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Properties\n",
    "\n",
    "- $I(X, Y) \\geq 0$ for any random variables $X$ and $Y$.\n",
    "  - $I(X, Y) = 0$ if and only if $X$ and $Y$ are independent.\n",
    "\n",
    "> 两个信息的共享信息量肯定大于等于零，等于零的时候两个信息毫无关联。\n",
    "\n",
    "- $I(X, Y) = I(Y, X)$ for any random variables $X$ and $Y$.\n",
    "\n",
    "> 两个信息的共享信息量和顺序无关。\n",
    "\n",
    "- if $X$ is an invertible function of $Y$, then $I(X, Y) = H(X) = H(Y)$.\n",
    "\n",
    "> 如果两个信息是可逆的，那么两个信息的共享信息量等于两个信息的信息量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pointwise Mutual Information\n",
    "\n",
    "> 记得在之前那个Expand\n",
    "\n",
    "When we worked with entropy at the beginning of this chapter, we were able to provide an interpretation of $-\\log(p_X(x))$\n",
    " as how surprised we were with the particular outcome. \n",
    "\n",
    "We may give a similar interpretation to the logarithmic term in the mutual information, which is often referred to as the pointwise mutual information:\n",
    "\n",
    "$$\n",
    "\\textrm{pmi}(x, y) = \\log\\frac{p_{X, Y}(x, y)}{p_X(x) p_Y(y)}.\n",
    "$$\n",
    "\n",
    "- the denominator is $p_X(x) p_Y(y)$ which is the probability of the two outcomes were independent\n",
    "- the numerator is $p_{X, Y}(x, y)$ which is the probability of the two outcomes were observed together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kullback-Leibler Divergence\n",
    "\n",
    "> 两个信息量做差，然后求均值\n",
    "\n",
    "> which provides a way to measure if two distributions are close together or not\n",
    "\n",
    "> 在空间中我们可以用范数来刻画两个点之间的距离，但是在概率空间中也有很多方法刻画分布之间的距离，但信息论提供了很好的方法。\n",
    "\n",
    "### Definition\n",
    "\n",
    "$$\n",
    "D_{\\textrm{KL}}(P\\|Q) = E_{x \\sim P} \\left[ \\log \\frac{p(x)}{q(x)} \\right].\n",
    "$$\n",
    "\n",
    "where\n",
    "- $D_{\\textrm{KL}}(P\\|Q)$ is the Kullback-Leibler divergence from $P$ to $Q$.\n",
    "- $P$ and $Q$ are two distributions.\n",
    "  - $P$ is the true distribution.\n",
    "  - $Q$ is the estimated distribution. \n",
    "- $p(x)$ is the p.d.f. or p.m.f. of $P$.\n",
    "- $q(x)$ is the p.d.f. or p.m.f. of $Q$.\n",
    "- $E_{x \\sim P}$ is the expectation of $x$ that follows the distribution $P$.\n",
    "- $D_{\\textrm{KL}}(P\\|Q)$ is the expectation of $\\log \\frac{p(x)}{q(x)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(p, q):\n",
    "    kl = p * torch.log2(p / q)\n",
    "    out = nansum(kl)\n",
    "    return out.abs().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties\n",
    "\n",
    "- non-negative\n",
    "  - $D_{\\textrm{KL}}(P\\|Q) \\geq 0$ for any distributions $P$ and $Q$.\n",
    "  - $D_{\\textrm{KL}}(P\\|Q) = 0$ if and only if $P = Q$.\n",
    "- non-symmetric\n",
    "  - $D_{\\textrm{KL}}(P\\|Q) \\neq D_{\\textrm{KL}}(Q\\|P)$\n",
    "- close relationship between KL divergence and mutual information\n",
    "$$\n",
    "D_{\\textrm{KL}}(P(X, Y)\\|P(X)P(Y)) = E_{(x, y) \\sim P} \\left[ \\log \\frac{p(x, y)}{p(x)p(y)} \\right] = I(X, Y)\n",
    "$$\n",
    "\n",
    "also equivalent to the following statements:\n",
    "- $E_Y \\{ D_{\\textrm{KL}}(P(X \\mid Y) \\ \\| \\ P(X)) \\}$\n",
    "- $E_X \\{ D_{\\textrm{KL}}(P(Y \\mid X) \\ \\| \\ P(Y)) \\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example \n",
    "\n",
    ">非对称性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "tensor_len = 10000\n",
    "p = torch.normal(0, 1, (tensor_len, ))\n",
    "q1 = torch.normal(-1, 1, (tensor_len, ))\n",
    "q2 = torch.normal(1, 1, (tensor_len, ))\n",
    "\n",
    "p = torch.sort(p)[0]\n",
    "q1 = torch.sort(q1)[0]\n",
    "q2 = torch.sort(q2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8582.0341796875, 8828.3095703125, 2.8290698237936858)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_pq1 = kl_divergence(p, q1)\n",
    "kl_pq2 = kl_divergence(p, q2)\n",
    "similar_percentage = abs(kl_pq1 - kl_pq2) / ((kl_pq1 + kl_pq2) / 2) * 100\n",
    "\n",
    "kl_pq1, kl_pq2, similar_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14130.125, 46.18621024399691)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_q2p = kl_divergence(q2, p)\n",
    "differ_percentage = abs(kl_q2p - kl_pq2) / ((kl_q2p + kl_pq2) / 2) * 100\n",
    "\n",
    "kl_q2p, differ_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Entropy\n",
    "\n",
    "### Formal Definition\n",
    "\n",
    "$$\n",
    "\\textrm{CE}(P, Q) = - E_{x \\sim P} [\\log(q(x))].\n",
    "$$\n",
    "\n",
    "where\n",
    "- $\\textrm{CE}(P, Q)$ is the cross entropy from $P$ to $Q$.\n",
    "- $P$ and $Q$ are two distributions.\n",
    "  - $P$ is the true distribution.\n",
    "  - $Q$ is the estimated distribution.\n",
    "- $q(x)$ is the p.d.f. or p.m.f. of $Q$.\n",
    "- $E_{x \\sim P}$ is the expectation of $x$ that follows the distribution $P$.\n",
    "\n",
    "By definition, we have\n",
    "$$\n",
    "\\textrm{CE}(P, Q) = H(P) + D_{\\textrm{KL}}(P\\|Q).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    ce = -torch.log(y_hat[range(len(y_hat)), y])\n",
    "    return ce.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9486)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.tensor([0, 2])\n",
    "preds = torch.tensor([[0.3, 0.6, 0.1], [0.2, 0.3, 0.5]])\n",
    "\n",
    "cross_entropy(preds, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties\n",
    "\n",
    "Cross-entropy is always used to define a loss function in the optimization problem.\n",
    "\n",
    "The following are equivalent:\n",
    "- Maximizing predictive probability of \n",
    "$Q$ for distribution $P$,  ($E_{x \\sim P} [\\log (q(x))]$)\n",
    "- Minimizing cross-entropy $\\textrm{CE}(P, Q)$\n",
    "- Minimizing KL divergence $D_{\\textrm{KL}}(P\\|Q)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `nn.NLLLoss`\n",
    "\n",
    "$$\n",
    " \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
    "        l_n = - w_{y_n} x_{n,y_n}, \\quad\n",
    "        w_{c} = \\text{weight}[c] \\cdot \\mathbb{1}\\{c \\not= \\text{ignore\\_index}\\},\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9486)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "nn.NLLLoss()(torch.log(preds), labels) # Negative Log Likelihood Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `nn.CrossEntropyLoss`\n",
    "\n",
    "> 这个函数它的默认第一个参数不是概率和为1的分布，而是网络最后一层的输出，然后自动执行`softmax`为你求一次概率。\n",
    "\n",
    "$$\n",
    "\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
    "          l_n = - w_{y_n} \\log \\frac{\\exp(x_{n,y_n})}{\\sum_{c=1}^C \\exp(x_{n,c})}\n",
    "          \\cdot \\mathbb{1}\\{y_n \\not= \\text{ignore\\_index}\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0466)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.CrossEntropyLoss()(preds, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
